{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPT4Jz0M73Vamr7U+2Sy5yB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gitan5hi/Bias-Detection-in-COMPAS-dataset/blob/main/Bias_Detection_in_COMPAS_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading dataset"
      ],
      "metadata": {
        "id": "OzLJETBiG7h2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle #in the terminal"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grqQYu4nJKgA",
        "outputId": "8e909994-3c97-4024-a088-66de45a6c863"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.8.3)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.3)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Uploading Kaggle API token\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "vwZ5EA67JUNs",
        "outputId": "990d9eca-0ea4-4f36-e0cb-4873f67234cf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-63e0cd33-2849-48bc-a06a-9f53a7aff4a7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-63e0cd33-2849-48bc-a06a-9f53a7aff4a7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"gitanshisingh\",\"key\":\"f1f70925013e0f03eef4fb75e0a7cc15\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Set up the Kaggle API credentials for use in the colab environment\n",
        "!mkdir -p ~/.kaggle   #creates a hidden directory for storing Kaggle credentials\n",
        "!mv kaggle.json ~/.kaggle/   #moves the downloaded API token to this secure location\n",
        "!chmod 600 ~/.kaggle/kaggle.json   #only the owner can access the file, protectin sensitive information"
      ],
      "metadata": {
        "id": "X70meWY_LQ3c"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Downloading the dataset\n",
        "!kaggle datasets download -d danofer/compass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PO-AplvCMf78",
        "outputId": "604fadf7-2e3f-4bff-a2f5-2906a1b38ac4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/danofer/compass\n",
            "License(s): DbCL-1.0\n",
            "Downloading compass.zip to /content\n",
            "  0% 0.00/2.72M [00:00<?, ?B/s]\n",
            "100% 2.72M/2.72M [00:00<00:00, 207MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip compass.zip -d compas_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKcV49aqNNVn",
        "outputId": "5749b61d-0892-4dbc-b094-1cf2870555be"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  compass.zip\n",
            "  inflating: compas_dataset/compas-scores-raw.csv  \n",
            "  inflating: compas_dataset/cox-violent-parsed.csv  \n",
            "  inflating: compas_dataset/cox-violent-parsed_filt.csv  \n",
            "  inflating: compas_dataset/propublicaCompassRecividism_data_fairml.csv/._propublica_data_for_fairml.csv  \n",
            "  inflating: compas_dataset/propublicaCompassRecividism_data_fairml.csv/propublica_data_for_fairml.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv(\"compas_dataset/propublicaCompassRecividism_data_fairml.csv/propublica_data_for_fairml.csv\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DYt_FGtNkkG",
        "outputId": "bf63ac5f-bb50-4395-f631-8d0ac7e49fb2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Two_yr_Recidivism  Number_of_Priors  score_factor  Age_Above_FourtyFive  \\\n",
            "0                  0                 0             0                     1   \n",
            "1                  1                 0             0                     0   \n",
            "2                  1                 4             0                     0   \n",
            "3                  0                 0             0                     0   \n",
            "4                  1                14             1                     0   \n",
            "\n",
            "   Age_Below_TwentyFive  African_American  Asian  Hispanic  Native_American  \\\n",
            "0                     0                 0      0         0                0   \n",
            "1                     0                 1      0         0                0   \n",
            "2                     1                 1      0         0                0   \n",
            "3                     0                 0      0         0                0   \n",
            "4                     0                 0      0         0                0   \n",
            "\n",
            "   Other  Female  Misdemeanor  \n",
            "0      1       0            0  \n",
            "1      0       0            0  \n",
            "2      0       0            0  \n",
            "3      1       0            1  \n",
            "4      0       0            0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Attributes Explained**\n",
        "\n",
        "* *Two_yr_Recidivism*: The target variable; indicates if a defendant was rearrested (recidivated) within two years (1=yes, 0=no).\n",
        "\n",
        "* *Number_of_Priors*: Count of prior offenses before the most recent arrest for each defendant.\n",
        "\n",
        "* *score_factor*: The COMPAS system assigns risk scores to defendants predicting their likelihood of recidivism (reoffending) within a certain period (e.g., two years) based on various behavioral, demographic, and criminal history factors.\n",
        "\n",
        "* *Age_Above_FourtyFive, Age_Below_TwentyFive*: Binary features showing if age is above 45 or below 25, respectively, encoding age group buckets for fairness analysis.\n",
        "\n",
        "* *African_American, Asian, Hispanic, Native_American, Other*: One-hot encoded columns for racial groups. These are mutually exclusive, so a single '1' per row indicates racial membership.\n",
        "\n",
        "* *Female*: Binary feature for gender.\n",
        "\n",
        "* *Misdemeanor*: Binary indicator for the type of charge (misdemeanor vs. felony).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "l4TfLUJbRn46"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project Outcome"
      ],
      "metadata": {
        "id": "jW7wK1VaUqf6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This analysis checks if the model that predicts whether someone might commit another crime is unfair to certain groups, like people of different  races, ages, or genders.\n",
        "\n",
        "\n",
        "The model looks at details such as how many crimes a person did before, their age, race, and if their current charge is serious or not.\n",
        "\n",
        "\n",
        "If a model is biased, it could mean certain people get harsher treatement from the justics system, not because of facts, but because of unfair preictions made by a computer.\n",
        "\n",
        "Bias detection helps ensure everyone gets equal treatment, and that the model's decisions are just and reliable for all backgrounds.\n"
      ],
      "metadata": {
        "id": "54EfvE72Uu_o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing"
      ],
      "metadata": {
        "id": "Vks6xtnKCLxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "QazZ2si41A5j"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalization\n",
        "scaler = MinMaxScaler()\n",
        "df['Number_of_Priors_Normalized'] = scaler.fit_transform(df[['Number_of_Priors']])"
      ],
      "metadata": {
        "id": "H-ZA_c8Pb5Vb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Look for correlation of Two_yr_Recidivism with other attributes\n",
        "print(df.info())\n",
        "correlation_matrix=df.corr()\n",
        "print(correlation_matrix[\"Two_yr_Recidivism\"].sort_values(ascending=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohK00qrECRmQ",
        "outputId": "55c8f0f0-3afc-4c22-e4ca-9acd549d4fd5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6172 entries, 0 to 6171\n",
            "Data columns (total 13 columns):\n",
            " #   Column                       Non-Null Count  Dtype  \n",
            "---  ------                       --------------  -----  \n",
            " 0   Two_yr_Recidivism            6172 non-null   int64  \n",
            " 1   Number_of_Priors             6172 non-null   int64  \n",
            " 2   score_factor                 6172 non-null   int64  \n",
            " 3   Age_Above_FourtyFive         6172 non-null   int64  \n",
            " 4   Age_Below_TwentyFive         6172 non-null   int64  \n",
            " 5   African_American             6172 non-null   int64  \n",
            " 6   Asian                        6172 non-null   int64  \n",
            " 7   Hispanic                     6172 non-null   int64  \n",
            " 8   Native_American              6172 non-null   int64  \n",
            " 9   Other                        6172 non-null   int64  \n",
            " 10  Female                       6172 non-null   int64  \n",
            " 11  Misdemeanor                  6172 non-null   int64  \n",
            " 12  Number_of_Priors_Normalized  6172 non-null   float64\n",
            "dtypes: float64(1), int64(12)\n",
            "memory usage: 627.0 KB\n",
            "None\n",
            "Two_yr_Recidivism              1.000000\n",
            "score_factor                   0.314832\n",
            "Number_of_Priors               0.290607\n",
            "Number_of_Priors_Normalized    0.290607\n",
            "African_American               0.140609\n",
            "Age_Below_TwentyFive           0.111027\n",
            "Native_American               -0.000049\n",
            "Asian                         -0.028115\n",
            "Other                         -0.045596\n",
            "Hispanic                      -0.050453\n",
            "Female                        -0.100911\n",
            "Misdemeanor                   -0.120332\n",
            "Age_Above_FourtyFive          -0.139490\n",
            "Name: Two_yr_Recidivism, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reweighing based on 'African_American' group\n",
        "group_counts = df['African_American'].value_counts().to_dict()\n",
        "total_samples = len(df)\n",
        "weights = {grp: total_samples/(len(group_counts)*count) for grp, count in group_counts.items()}\n",
        "sample_weights = df['African_American'].map(weights)"
      ],
      "metadata": {
        "id": "XCLk2SIh1olb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sampling: oversample minority African_American group to balance dataset\n",
        "df_majority = df[df['African_American'] == 0]\n",
        "df_minority = df[df['African_American'] == 1]\n",
        "df_minority_upsampled = resample(df_minority, replace=True, n_samples=len(df_majority), random_state=42)\n",
        "df_balanced = pd.concat([df_majority, df_minority_upsampled]).sample(frac=1, random_state=42).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "sTG2SzJWR60T"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature transformation\n",
        "features_to_use = ['Number_of_Priors', 'score_factor', 'Age_Above_FourtyFive', 'Age_Below_TwentyFive', 'Misdemeanor', 'Number_of_Priors_Normalized']\n",
        "df_balanced_features = df_balanced[features_to_use]\n",
        "df_balanced_target = df_balanced['Two_yr_Recidivism']"
      ],
      "metadata": {
        "id": "3Pg2k78S4CPX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_balanced_features, df_balanced_target, test_size=0.2, random_state=42)\n",
        "print(f\"Before balancing: {Counter(df['African_American'])}\")\n",
        "print(f\"After balancing: {Counter(df_balanced['African_American'])}\")"
      ],
      "metadata": {
        "id": "iIdR95e7bKau",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fec1f865-eeaa-43c0-9acd-0f66f812a257"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before balancing: Counter({1: 3175, 0: 2997})\n",
            "After balancing: Counter({0: 2997, 1: 2997})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Development and Training"
      ],
      "metadata": {
        "id": "ImVEbDG8cBKY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Different *Predictive Models* for binary outcome (Logistic regression, Decision Tree) using features from the dataset."
      ],
      "metadata": {
        "id": "68KWG-RldFVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Train logistic regression model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "logreg=LogisticRegression(max_iter=100)\n",
        "logreg.fit(X_train, y_train)\n",
        "#Predict and evaluate accuracy\n",
        "logreg_preds=logreg.predict(X_test)\n",
        "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, logreg_preds))"
      ],
      "metadata": {
        "id": "6XB_y4EbcOxd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26d3ae14-5032-4fba-fa79-dc1dbbe8098c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 0.6872393661384487\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Regression (a Predictive ML model) is not used here because the outcome is binary and it predicts continuous values."
      ],
      "metadata": {
        "id": "t3CapX83ecFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Train Random Forest model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "rf=RandomForestClassifier(n_estimators=10, random_state=42)\n",
        "rf.fit(X_train,y_train)\n",
        "rf_preds=rf.predict(X_test)\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, rf_preds))"
      ],
      "metadata": {
        "id": "58g5vjXbgV6s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "508240ae-dca4-4833-a00f-8b55dc62852f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.6930775646371977\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bias Detection and Measurement"
      ],
      "metadata": {
        "id": "2_2o30tQiTuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# For bias metrics, put sensitive attributes aside for group-wise evaluation\n",
        "# List of individual minority columns\n",
        "minority_columns = ['African_American', 'Asian', 'Hispanic', 'Native_American', 'Other','Female']\n",
        "\n",
        "#Sums values across minority columns for each row to check if a person belongs to any minority group (sum > 0).\n",
        "#Converts this boolean result into binary integers (1 if minority; 0 otherwise), creating a new series any_minority indicating minority status for group-wise bias evaluation.\n",
        "#any_minority = (df.loc[y_test.index, minority_columns].sum(axis=1) > 0).astype(int)\n",
        "\n",
        "def disparity_impact(y_true, y_pred, sensitive_attr):\n",
        "    # Ratio of favorable outcomes for protected vs unprotected group\n",
        "    favorable_protected = np.mean(y_pred[sensitive_attr == 1] == 0)\n",
        "    favorable_unprotected = np.mean(y_pred[sensitive_attr == 0] == 0)\n",
        "    return favorable_protected / favorable_unprotected\n",
        "\n",
        "def statistical_parity_difference(y_pred, sensitive_attr):\n",
        "    p_privileged = np.mean(y_pred[sensitive_attr == 0] == 0)\n",
        "    p_protected = np.mean(y_pred[sensitive_attr == 1] == 0)\n",
        "    return p_protected - p_privileged\n",
        "\n",
        "def false_positive_rate_difference(y_true, y_pred, sensitive_attr):\n",
        "    cm_protected = confusion_matrix(y_true[sensitive_attr == 1], y_pred[sensitive_attr == 1])\n",
        "    cm_unprotected = confusion_matrix(y_true[sensitive_attr == 0], y_pred[sensitive_attr == 0])\n",
        "\n",
        "    def safe_fpr(cm):\n",
        "      if cm.shape == (2,2):\n",
        "        tn,fp=cm[0,0],cm[0,1]\n",
        "        if (fp+tn)==0:\n",
        "          return 0\n",
        "        else:\n",
        "          return fp/(fp+tn)\n",
        "      else:\n",
        "        return 0\n",
        "    fpr_protected = safe_fpr(cm_protected)\n",
        "    fpr_unprotected = safe_fpr(cm_unprotected)\n",
        "    return fpr_protected - fpr_unprotected\n",
        "\n",
        "#Dictionary to store fairness metrics for each minority group\n",
        "fairness_metrics={}\n",
        "\n",
        "# Interate over each minority group column to calculate metrics separately\n",
        "for group in minority_columns:\n",
        "  sensitive_attr = df.loc[y_test.index, group]\n",
        "\n",
        "  di = disparity_impact(y_test, logreg_preds, sensitive_attr)\n",
        "  spd = statistical_parity_difference(logreg_preds, sensitive_attr)\n",
        "  fprd = false_positive_rate_difference(y_test, logreg_preds, sensitive_attr)\n",
        "\n",
        "  fairness_metrics[group] = {\n",
        "        'Disparate_Impact': di,\n",
        "        'Statistical_Parity_Difference': spd,\n",
        "        'False_Positive_Rate_Difference': fprd\n",
        "  }\n",
        "\n",
        "# Print the fairness metrics grouped by minority category\n",
        "for group, metrics in fairness_metrics.items():\n",
        "    print(f\"Metrics for {group}:\")\n",
        "    print(f\"  Disparate Impact: {metrics['Disparate_Impact']:.3f}\")\n",
        "    print(f\"  Statistical Parity Difference: {metrics['Statistical_Parity_Difference']:.3f}\")\n",
        "    print(f\"  False Positive Rate Difference: {metrics['False_Positive_Rate_Difference']:.3f}\\n\")\n"
      ],
      "metadata": {
        "id": "jdGtRvVnjEvv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9a19060-905d-4d4d-b346-63dd79f31d64"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics for African_American:\n",
            "  Disparate Impact: 0.984\n",
            "  Statistical Parity Difference: -0.009\n",
            "  False Positive Rate Difference: 0.021\n",
            "\n",
            "Metrics for Asian:\n",
            "  Disparate Impact: 1.138\n",
            "  Statistical Parity Difference: 0.081\n",
            "  False Positive Rate Difference: -0.080\n",
            "\n",
            "Metrics for Hispanic:\n",
            "  Disparate Impact: 1.026\n",
            "  Statistical Parity Difference: 0.015\n",
            "  False Positive Rate Difference: -0.021\n",
            "\n",
            "Metrics for Native_American:\n",
            "  Disparate Impact: 1.708\n",
            "  Statistical Parity Difference: 0.414\n",
            "  False Positive Rate Difference: -0.247\n",
            "\n",
            "Metrics for Other:\n",
            "  Disparate Impact: 0.821\n",
            "  Statistical Parity Difference: -0.106\n",
            "  False Positive Rate Difference: 0.046\n",
            "\n",
            "Metrics for Female:\n",
            "  Disparate Impact: 1.071\n",
            "  Statistical Parity Difference: 0.041\n",
            "  False Positive Rate Difference: -0.065\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}